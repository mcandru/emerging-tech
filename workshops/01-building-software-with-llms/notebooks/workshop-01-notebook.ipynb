{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Workshop 1: Building Software with LLMs\n",
        "\n",
        "Welcome! This notebook will guide you through using LLMs via API.\n",
        "\n",
        "**Before you start**, make sure you have:\n",
        "1. Your Gemini API key from [aistudio.google.com](https://aistudio.google.com)\n",
        "2. Added it to Colab Secrets (üîë icon in left sidebar) with the name `GOOGLE_API_KEY`"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üîß Setup\n",
        "\n",
        "Run this cell first to install the library and configure your API key."
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Install the Google AI library (only needs to run once)\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "# Import and configure\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Get your API key from Colab secrets\n",
        "try:\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    print(\"‚úÖ API key configured successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error: Could not find API key.\")\n",
        "    print(\"   Make sure you've added GOOGLE_API_KEY to your Colab secrets (üîë icon)\")\n",
        "    print(f\"   Error details: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test - run this to make sure everything works\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "response = model.generate_content(\"Say hello in three different languages\")\n",
        "print(\"Test response:\")\n",
        "print(response.text)\n",
        "print(\"\\n‚úÖ If you see greetings above, you're all set!\")"
      ],
      "metadata": {
        "id": "test-setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üìö Part 3: Your First API Calls\n",
        "\n",
        "Now let's explore what you can do with the API!"
      ],
      "metadata": {
        "id": "part3-header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.1: Basic API Call\n",
        "\n",
        "The simplest way to use the API - send a prompt, get a response."
      ],
      "metadata": {
        "id": "ex31-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "prompt = \"Explain what an API is in exactly two sentences.\"\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ex31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ YOUR TURN: Modify the prompt above!\n",
        "# Try:\n",
        "#   - Change \"two sentences\" to \"one sentence\" or \"three bullet points\"\n",
        "#   - Change the topic from APIs to something else\n",
        "\n",
        "prompt = \"YOUR PROMPT HERE\"  # <-- Edit this!\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ex31-try"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.2: Processing Multiple Items\n",
        "\n",
        "One of the API's superpowers: processing many items automatically!"
      ],
      "metadata": {
        "id": "ex32-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A list of tech buzzwords we want explained simply\n",
        "buzzwords = [\n",
        "    \"blockchain\",\n",
        "    \"machine learning\",\n",
        "    \"quantum computing\",\n",
        "    \"edge computing\",\n",
        "    \"digital twin\"\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "print(\"Tech Jargon Translator\")\n",
        "print(\"=\" * 50)\n",
        "print()\n",
        "\n",
        "for word in buzzwords:\n",
        "    prompt = f\"Explain '{word}' in one simple sentence that a teenager would understand.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    print(f\"üìå {word.upper()}\")\n",
        "    print(f\"   {response.text}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "ex32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ YOUR TURN:\n",
        "#   - Add more buzzwords to the list\n",
        "#   - Change the target audience (e.g., \"a 5-year-old\", \"a CEO\", \"your grandma\")\n",
        "\n",
        "my_buzzwords = [\n",
        "    # Add your buzzwords here!\n",
        "]\n",
        "\n",
        "target_audience = \"a teenager\"  # <-- Change this!\n",
        "\n",
        "for word in my_buzzwords:\n",
        "    prompt = f\"Explain '{word}' in one simple sentence that {target_audience} would understand.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    print(f\"üìå {word.upper()}\")\n",
        "    print(f\"   {response.text}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "ex32-try"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.3: System Instructions\n",
        "\n",
        "Give the model a persistent \"personality\" or set of rules."
      ],
      "metadata": {
        "id": "ex33-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    'gemini-2.0-flash',\n",
        "    system_instruction=\"\"\"You are a dramatic movie trailer narrator.\n",
        "\n",
        "    Rules:\n",
        "    - Everything you say should sound like it's from an epic movie trailer\n",
        "    - Use dramatic pauses (written as \"...\")\n",
        "    - Keep responses short but INTENSE\n",
        "    - End with a tagline\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Now all responses will follow these rules\n",
        "response = model.generate_content(\"What is photosynthesis?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ex33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ YOUR TURN: Create your own character!\n",
        "# Ideas: sarcastic robot, overly enthusiastic fitness instructor,\n",
        "#        mysterious fortune teller, grumpy medieval knight...\n",
        "\n",
        "my_model = genai.GenerativeModel(\n",
        "    'gemini-2.0-flash',\n",
        "    system_instruction=\"\"\"YOUR CHARACTER HERE\n",
        "\n",
        "    Rules:\n",
        "    - Rule 1\n",
        "    - Rule 2\n",
        "    - Rule 3\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "response = my_model.generate_content(\"What is the weather like today?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ex33-try"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.4: Structured Output with JSON\n",
        "\n",
        "Get data in a specific format you can use in your code."
      ],
      "metadata": {
        "id": "ex34-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "prompt = \"\"\"Analyze this technology and return your analysis as JSON:\n",
        "\n",
        "Technology: Virtual Reality in Education\n",
        "\n",
        "Return a JSON object with these exact fields:\n",
        "{\n",
        "    \"technology_name\": \"...\",\n",
        "    \"maturity_level\": \"emerging/growing/mature\",\n",
        "    \"time_to_mainstream\": \"...\",\n",
        "    \"top_3_benefits\": [\"...\", \"...\", \"...\"],\n",
        "    \"top_3_challenges\": [\"...\", \"...\", \"...\"],\n",
        "    \"confidence_score\": 0.0 to 1.0\n",
        "}\n",
        "\n",
        "Return ONLY the JSON, no other text.\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(\"Raw response:\")\n",
        "print(response.text)\n",
        "\n",
        "# Try to parse it as JSON\n",
        "try:\n",
        "    # Clean up the response (remove markdown code blocks if present)\n",
        "    json_text = response.text.strip()\n",
        "    if json_text.startswith(\"```\"):\n",
        "        json_text = json_text.split(\"```\")[1]\n",
        "        if json_text.startswith(\"json\"):\n",
        "            json_text = json_text[4:]\n",
        "\n",
        "    data = json.loads(json_text)\n",
        "    print(\"\\n‚úÖ Successfully parsed as JSON!\")\n",
        "    print(f\"Technology: {data['technology_name']}\")\n",
        "    print(f\"Maturity: {data['maturity_level']}\")\n",
        "    print(f\"Benefits: {', '.join(data['top_3_benefits'])}\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"\\n‚ùå Couldn't parse as JSON: {e}\")"
      ],
      "metadata": {
        "id": "ex34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ YOUR TURN: Analyze a technology of your choice!\n",
        "\n",
        "my_technology = \"YOUR TECHNOLOGY HERE\"  # <-- Change this!\n",
        "\n",
        "prompt = f\"\"\"Analyze this technology and return your analysis as JSON:\n",
        "\n",
        "Technology: {my_technology}\n",
        "\n",
        "Return a JSON object with these exact fields:\n",
        "{{\n",
        "    \"technology_name\": \"...\",\n",
        "    \"maturity_level\": \"emerging/growing/mature\",\n",
        "    \"time_to_mainstream\": \"...\",\n",
        "    \"top_3_benefits\": [\"...\", \"...\", \"...\"],\n",
        "    \"top_3_challenges\": [\"...\", \"...\", \"...\"],\n",
        "    \"confidence_score\": 0.0 to 1.0\n",
        "}}\n",
        "\n",
        "Return ONLY the JSON, no other text.\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Parse and display\n",
        "try:\n",
        "    json_text = response.text.strip()\n",
        "    if json_text.startswith(\"```\"):\n",
        "        json_text = json_text.split(\"```\")[1]\n",
        "        if json_text.startswith(\"json\"):\n",
        "            json_text = json_text[4:]\n",
        "\n",
        "    data = json.loads(json_text)\n",
        "    print(f\"\\nüìä Analysis of: {data['technology_name']}\")\n",
        "    print(f\"   Maturity: {data['maturity_level']}\")\n",
        "    print(f\"   Time to mainstream: {data['time_to_mainstream']}\")\n",
        "    print(f\"   Confidence: {data['confidence_score']}\")\n",
        "    print(f\"\\n   Benefits:\")\n",
        "    for b in data['top_3_benefits']:\n",
        "        print(f\"   ‚úì {b}\")\n",
        "    print(f\"\\n   Challenges:\")\n",
        "    for c in data['top_3_challenges']:\n",
        "        print(f\"   ‚úó {c}\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"\\n‚ùå Couldn't parse as JSON: {e}\")\n",
        "    print(\"Raw response:\")\n",
        "    print(response.text)"
      ],
      "metadata": {
        "id": "ex34-try"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.5: Temperature and Creativity\n",
        "\n",
        "The `temperature` parameter controls how \"creative\" or \"random\" the output is."
      ],
      "metadata": {
        "id": "ex35-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "prompt = \"Suggest a name for a new AI-powered study app\"\n",
        "\n",
        "print(\"Low temperature (0.1) - More predictable:\")\n",
        "response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config=genai.GenerationConfig(temperature=0.1)\n",
        ")\n",
        "print(response.text)\n",
        "\n",
        "print(\"\\nHigh temperature (1.0) - More creative:\")\n",
        "response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config=genai.GenerationConfig(temperature=1.0)\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ex35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell multiple times and see how the outputs differ!\n",
        "\n",
        "print(\"Low temp (run a few times - should be similar):\")\n",
        "for i in range(3):\n",
        "    response = model.generate_content(\n",
        "        \"Name one fruit\",\n",
        "        generation_config=genai.GenerationConfig(temperature=0.1)\n",
        "    )\n",
        "    print(f\"  {i+1}. {response.text.strip()}\")\n",
        "\n",
        "print(\"\\nHigh temp (run a few times - should vary):\")\n",
        "for i in range(3):\n",
        "    response = model.generate_content(\n",
        "        \"Name one fruit\",\n",
        "        generation_config=genai.GenerationConfig(temperature=1.0)\n",
        "    )\n",
        "    print(f\"  {i+1}. {response.text.strip()}\")"
      ],
      "metadata": {
        "id": "ex35-demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.6: Images via the API üñºÔ∏è\n",
        "\n",
        "You can also send images to the API! First, upload an image to Colab:\n",
        "1. Click the **üìÅ folder icon** in the left sidebar\n",
        "2. Click the **upload icon** (arrow pointing up)\n",
        "3. Select any image from your computer"
      ],
      "metadata": {
        "id": "ex36-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "# Load your uploaded image (change the filename to match yours!)\n",
        "image = PIL.Image.open('your_image.jpg')  # <-- CHANGE THIS to your filename!\n",
        "\n",
        "# Ask about the image\n",
        "response = model.generate_content([\n",
        "    \"Describe this image in a fun, creative way.\",\n",
        "    image\n",
        "])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ex36-basic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different prompts with the same image!\n",
        "\n",
        "prompts = [\n",
        "    \"What colours are most prominent in this image?\",\n",
        "    \"Write a haiku inspired by this image.\",\n",
        "    \"If this image was a movie scene, what genre would it be?\",\n",
        "    \"What questions does this image raise?\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    response = model.generate_content([prompt, image])\n",
        "    print(f\"üì∏ {prompt}\")\n",
        "    print(f\"   {response.text}\\n\")"
      ],
      "metadata": {
        "id": "ex36-multiple-prompts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ BONUS: Process multiple images at once!\n",
        "import os\n",
        "\n",
        "# Find all jpg/png files in your Colab environment\n",
        "image_files = [f for f in os.listdir('.') if f.endswith(('.jpg', '.png', '.jpeg', '.gif', '.webp'))]\n",
        "\n",
        "if image_files:\n",
        "    print(f\"Found {len(image_files)} images\\n\")\n",
        "    for filename in image_files:\n",
        "        image = PIL.Image.open(filename)\n",
        "        response = model.generate_content([\n",
        "            \"In exactly 10 words, describe what's in this image.\",\n",
        "            image\n",
        "        ])\n",
        "        print(f\"üñºÔ∏è {filename}: {response.text}\")\n",
        "else:\n",
        "    print(\"No images found! Upload some images using the folder icon in the sidebar.\")"
      ],
      "metadata": {
        "id": "ex36-batch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üõ†Ô∏è Part 4: Build Something Useful!\n",
        "\n",
        "Choose ONE of the following mini-projects. Each one has starter code you can build on."
      ],
      "metadata": {
        "id": "part4-header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option A: Essay Feedback Tool üìù\n",
        "\n",
        "Build a tool that gives structured feedback on essay paragraphs."
      ],
      "metadata": {
        "id": "optionA-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION A: Essay Feedback Tool\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    'gemini-2.0-flash',\n",
        "    system_instruction=\"\"\"You are a supportive academic writing tutor.\n",
        "    Provide constructive feedback that helps students improve.\n",
        "    Be specific about what's good and what could be better.\n",
        "    Keep feedback concise - max 150 words.\"\"\"\n",
        ")\n",
        "\n",
        "def get_essay_feedback(paragraph, assignment_type=\"general essay\"):\n",
        "    \"\"\"Get feedback on an essay paragraph.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Assignment type: {assignment_type}\n",
        "\n",
        "    Student's paragraph:\n",
        "    \"{paragraph}\"\n",
        "\n",
        "    Provide feedback on:\n",
        "    1. Clarity (is the main point clear?)\n",
        "    2. Evidence (are claims supported?)\n",
        "    3. Structure (does it flow well?)\n",
        "    4. One specific suggestion for improvement\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Test it\n",
        "test_paragraph = \"\"\"\n",
        "AI is going to change everything in education. Many experts believe this.\n",
        "Students will learn better with AI tutors. Traditional teaching will become\n",
        "obsolete. This is definitely going to happen in the next few years.\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"ESSAY FEEDBACK TOOL\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nYour paragraph:\")\n",
        "print(test_paragraph)\n",
        "print(\"\\nFeedback:\")\n",
        "print(get_essay_feedback(test_paragraph, \"argumentative essay\"))"
      ],
      "metadata": {
        "id": "optionA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ CHALLENGES for Option A:\n",
        "# 1. Try it with different paragraphs\n",
        "# 2. Add a scoring system (1-5 stars for each category)\n",
        "# 3. Add an option for different feedback styles (gentle, direct, detailed)\n",
        "\n",
        "# Your code here!\n"
      ],
      "metadata": {
        "id": "optionA-challenges"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option B: Research Question Generator üî¨\n",
        "\n",
        "Build a tool that generates research questions from a topic."
      ],
      "metadata": {
        "id": "optionB-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION B: Research Question Generator\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "def generate_research_questions(topic, discipline=\"general\", difficulty=\"undergraduate\"):\n",
        "    \"\"\"Generate research questions for a given topic.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Generate 5 research questions about: {topic}\n",
        "    Academic discipline: {discipline}\n",
        "    Level: {difficulty}\n",
        "\n",
        "    For each question, provide:\n",
        "    - The research question itself\n",
        "    - Why it's interesting/important\n",
        "    - What kind of methods might address it\n",
        "\n",
        "    Make questions specific enough to be researchable but broad enough\n",
        "    to allow for original contribution.\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Test it\n",
        "topic = \"The impact of social media on academic integrity\"\n",
        "print(\"=\" * 50)\n",
        "print(\"RESEARCH QUESTION GENERATOR\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nTopic: {topic}\")\n",
        "print(\"\\nGenerated Questions:\")\n",
        "print(generate_research_questions(topic, \"psychology\", \"undergraduate\"))"
      ],
      "metadata": {
        "id": "optionB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ CHALLENGES for Option B:\n",
        "# 1. Try different topics relevant to your interests\n",
        "# 2. Add a \"controversial/safe\" parameter\n",
        "# 3. Make it return structured data (JSON) instead of plain text\n",
        "\n",
        "# Your code here!\n"
      ],
      "metadata": {
        "id": "optionB-challenges"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option C: Tech Trend Analyzer üìä\n",
        "\n",
        "Build a tool that analyzes whether a technology prediction is plausible."
      ],
      "metadata": {
        "id": "optionC-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION C: Tech Trend Analyzer\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "def analyze_prediction(prediction, timeframe=\"2-3 years\"):\n",
        "    \"\"\"Analyze a technology prediction and return structured analysis.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this technology prediction:\n",
        "    \"{prediction}\"\n",
        "\n",
        "    Timeframe: {timeframe}\n",
        "\n",
        "    Return a JSON object with:\n",
        "    {{\n",
        "        \"prediction\": \"the original prediction\",\n",
        "        \"plausibility_score\": 1-10,\n",
        "        \"supporting_factors\": [\"factor1\", \"factor2\", \"factor3\"],\n",
        "        \"opposing_factors\": [\"factor1\", \"factor2\", \"factor3\"],\n",
        "        \"key_uncertainties\": [\"uncertainty1\", \"uncertainty2\"],\n",
        "        \"verdict\": \"likely/possible/unlikely\",\n",
        "        \"reasoning\": \"2-3 sentences explaining your verdict\"\n",
        "    }}\n",
        "\n",
        "    Return ONLY valid JSON, no other text.\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Clean and parse\n",
        "    json_text = response.text.strip()\n",
        "    if json_text.startswith(\"```\"):\n",
        "        json_text = json_text.split(\"```\")[1]\n",
        "        if json_text.startswith(\"json\"):\n",
        "            json_text = json_text[4:]\n",
        "\n",
        "    try:\n",
        "        return json.loads(json_text)\n",
        "    except:\n",
        "        return {\"error\": \"Could not parse response\", \"raw\": response.text}\n",
        "\n",
        "# Test it\n",
        "prediction = \"By 2027, most university exams will be conducted using AI proctoring systems\"\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"TECH TREND ANALYZER\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nPrediction: {prediction}\")\n",
        "print(\"\\nAnalysis:\")\n",
        "\n",
        "result = analyze_prediction(prediction)\n",
        "if \"error\" not in result:\n",
        "    print(f\"Plausibility: {result['plausibility_score']}/10\")\n",
        "    print(f\"Verdict: {result['verdict']}\")\n",
        "    print(f\"\\nSupporting factors:\")\n",
        "    for f in result['supporting_factors']:\n",
        "        print(f\"  ‚úì {f}\")\n",
        "    print(f\"\\nOpposing factors:\")\n",
        "    for f in result['opposing_factors']:\n",
        "        print(f\"  ‚úó {f}\")\n",
        "    print(f\"\\nReasoning: {result['reasoning']}\")\n",
        "else:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "optionC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ CHALLENGES for Option C:\n",
        "# 1. Try predictions relevant to your assignment topic\n",
        "# 2. Add a \"compare two predictions\" function\n",
        "# 3. Add confidence intervals to the plausibility score\n",
        "\n",
        "# Your code here!\n"
      ],
      "metadata": {
        "id": "optionC-challenges"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üì¶ Submission\n",
        "\n",
        "Before you leave:\n",
        "1. Make sure your code runs (Runtime ‚Üí Run all)\n",
        "2. Download this notebook: File ‚Üí Download ‚Üí Download .ipynb\n",
        "3. Upload to Teams in the Workshop 1 channel\n",
        "4. Add a comment describing what you built and one thing you learned"
      ],
      "metadata": {
        "id": "submission"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üéÅ Bonus: Going Further\n",
        "\n",
        "Finished early? Try these!"
      ],
      "metadata": {
        "id": "bonus-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BONUS 1: Try different models\n",
        "# Gemini has different model sizes with different capabilities\n",
        "\n",
        "model_flash = genai.GenerativeModel('gemini-2.0-flash')  # Fast, cheap\n",
        "model_pro = genai.GenerativeModel('gemini-1.5-pro')      # More capable\n",
        "\n",
        "prompt = \"Write a haiku about machine learning\"\n",
        "\n",
        "print(\"Flash model:\")\n",
        "print(model_flash.generate_content(prompt).text)\n",
        "\n",
        "print(\"\\nPro model:\")\n",
        "print(model_pro.generate_content(prompt).text)"
      ],
      "metadata": {
        "id": "bonus1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BONUS 2: Add error handling with retry\n",
        "\n",
        "def safe_generate(model, prompt, max_retries=3):\n",
        "    \"\"\"Generate with automatic retry on failure.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                print(\"Waiting 2 seconds before retrying...\")\n",
        "                time.sleep(2)\n",
        "    return None\n",
        "\n",
        "# Test it\n",
        "result = safe_generate(model, \"What is the meaning of life?\")\n",
        "if result:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "bonus2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BONUS 3: Chain multiple calls together\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "# First call: brainstorm\n",
        "print(\"Step 1: Brainstorming...\")\n",
        "ideas = model.generate_content(\"List 5 ways AI might change libraries in the next decade\")\n",
        "print(ideas.text)\n",
        "\n",
        "# Second call: evaluate the ideas\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Step 2: Evaluating the most impactful...\")\n",
        "evaluation = model.generate_content(f\"\"\"\n",
        "From these ideas:\n",
        "{ideas.text}\n",
        "\n",
        "Pick the MOST impactful one and explain:\n",
        "1. Why you chose it\n",
        "2. What would need to happen for it to come true\n",
        "3. Who would benefit most\n",
        "\"\"\")\n",
        "print(evaluation.text)"
      ],
      "metadata": {
        "id": "bonus3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üìö Quick Reference\n",
        "\n",
        "```python\n",
        "# Setup\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"YOUR_KEY\")\n",
        "\n",
        "# Create model\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "# Simple generation\n",
        "response = model.generate_content(\"Your prompt here\")\n",
        "print(response.text)\n",
        "\n",
        "# With system instructions\n",
        "model = genai.GenerativeModel(\n",
        "    'gemini-2.0-flash',\n",
        "    system_instruction=\"You are a helpful assistant...\"\n",
        ")\n",
        "\n",
        "# With temperature\n",
        "response = model.generate_content(\n",
        "    \"Your prompt\",\n",
        "    generation_config=genai.GenerationConfig(temperature=0.7)\n",
        ")\n",
        "```\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "| Problem | Solution |\n",
        "|---------|----------|\n",
        "| \"API key not found\" | Check your Colab secrets (üîë icon) |\n",
        "| \"Quota exceeded\" | Wait a minute, you're making too many requests |\n",
        "| JSON won't parse | Ask the model to return \"ONLY valid JSON\" |\n",
        "| Response is cut off | Ask for a shorter response in your prompt |"
      ],
      "metadata": {
        "id": "reference"
      }
    }
  ]
}
